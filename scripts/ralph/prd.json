{
  "projectName": "Lomar Refined Build Extraction",
  "branchName": "main",
  "targetUrl": "https://www.lomarefined.com/blogs/journal",
  "outputDir": "scraped_builds/lomar_refined",
  "pipelineStage": "3_build_extraction",
  "sourceId": "lomar_refined",
  "userStories": [
    {
      "id": "BUILD-001",
      "title": "Read build extraction schema for output format",
      "acceptanceCriteria": [
        "Read schema/build_extraction_schema.json to understand output format",
        "Identify required fields: id, url, title, make, model, year, modifications_raw",
        "Understand modifications array structure: name, category, confidence"
      ],
      "priority": 1,
      "passes": true,
      "notes": "Schema defines build record structure. Must match exactly for compatibility."
    },
    {
      "id": "BUILD-002",
      "title": "Analyze HTML structure for build data patterns",
      "acceptanceCriteria": [
        "Examine scraped HTML files to identify data patterns",
        "Map vehicle identification: make (Ferrari, Lamborghini, etc.), model (SF90, Urus, etc.)",
        "Map horsepower figures (stock and tuned)",
        "Map wheel specifications (brand, size, finish)",
        "Map performance upgrades (downpipe, exhaust, tuning stages)"
      ],
      "priority": 2,
      "passes": true,
      "notes": "LOMA content follows consistent pattern: Vehicle + Wheels + Performance Tuning"
    },
    {
      "id": "BUILD-003",
      "title": "Create build extraction script",
      "acceptanceCriteria": [
        "Create extract_builds.py script",
        "Parse HTML from scraped files (or MCP JSON data)",
        "Extract vehicle: make, model, year (if available)",
        "Extract horsepower: stock_hp, tuned_hp",
        "Extract modifications: wheels, downpipe, exhaust, tuning, suspension",
        "Use build_id_generator.py to generate build_id from URL",
        "Output to builds.json matching schema format"
      ],
      "priority": 3,
      "passes": true,
      "notes": "MCP webReader returns structured JSON with title/content. Parse this instead of raw HTML."
    },
    {
      "id": "BUILD-004",
      "title": "Extract all builds and update pipeline counts",
      "acceptanceCriteria": [
        "Run extract_builds.py to completion",
        "Verify builds.json has 30 build records (one per URL)",
        "Update sources.json: builds=30",
        "Verify each build has required schema fields"
      ],
      "priority": 4,
      "passes": true,
      "notes": "Expected 30 builds from 30 scraped URLs"
    }
  ]
}
