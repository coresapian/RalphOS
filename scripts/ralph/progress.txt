# Ralph Progress Log
Started: 2026-01-06

---
## CURRENT PROJECT: OnAllCylinders Featured Vehicles Scraper
Project: OnAllCylinders Featured Vehicles Scraper
Target: https://www.onallcylinders.com/category/rods-rides-rigs/

## Codebase Patterns
- **SOURCES QUEUE**: Check `scripts/ralph/sources.json` for all target sources
- **DIRECTORY STRUCTURE**: Each source gets its own folder in `scraped_builds/{source}/`
- **AUTO-SETUP**: Always check if `outputDir` exists, create if not (including urls.json, html/)
- **URL STORAGE**: urls.json format: `{"urls": [...], "lastUpdated": "ISO8601", "totalCount": N}`
- **RATE LIMITING**: Always use 1.5s+ delay between requests
- **PROGRESS TRACKING**: Save scrape_progress.json to allow resuming
- **MANIFEST**: Create manifest.json after scraping with url, filename, scraped_at, file_size_bytes
- **MULTI-SOURCE**: When PRD complete, update sources.json status and generate next PRD

## Current Project
- Target site: https://www.onallcylinders.com/category/rods-rides-rigs/
- Output dir: scraped_builds/onallcylinders/
- Standard pagination (45 pages), URL pattern: /page/2/, /page/3/, etc
- ~746 articles in Featured Vehicles category

## Directory Structure
```
scraped_builds/
├── martiniworks/           # Previous project (COMPLETED)
│   ├── html/               # 999 HTML files
│   ├── manifest.json
│   ├── scrape_progress.json
│   └── urls.json
│
└── onallcylinders/         # Current project
    ├── html/               # HTML files go here
    └── urls.json           # URLs go here
```

## Key Files
- scripts/ralph/prd.json - Task definitions
- scripts/ralph/progress.txt - This file  
- scraped_builds/onallcylinders/urls.json - Discovered URLs
- scraped_builds/onallcylinders/html/ - Saved HTML files
- scraped_builds/onallcylinders/manifest.json - Scrape metadata (create after scraping)

## Site Structure (from inspection)
- Gallery URL: https://www.onallcylinders.com/category/rods-rides-rigs/
- Pagination: 45 pages, /page/N/ URL pattern
- Articles include: SEMA coverage, Lot Shots, Build features, Tech articles
- Individual articles have slugs like /[year]/[month]/[article-slug]/

---

## [2026-01-06] - US-001 (OnAllCylinders) ✅
- Created scraper directory structure for OnAllCylinders
- Files created:
  - scraped_builds/onallcylinders/urls.json (empty template)
  - scraped_builds/onallcylinders/html/ (directory for HTML files)
- **Learnings:**
  - Organized scraped_builds/ by source (martiniworks/, onallcylinders/)
  - Each scrape project gets its own subfolder

---

## [2026-01-06] - US-004 (OnAllCylinders) ✅
- Executed full scrape of all 446 articles from OnAllCylinders
- Actual count was 446 (not ~746 as initially estimated)
- Files created:
  - 446 HTML files in scraped_builds/onallcylinders/html/
  - manifest.json with metadata (url, filename, title, scraped_at, file_size_bytes)
- Total data size: 54.4 MB
- Scrape duration: ~15 minutes (446 URLs × 1.5s delay)
- **Learnings:**
  - Estimated article counts from pagination can be inaccurate
  - OnAllCylinders site has fewer articles than pagination suggested
  - Running scraper in background with TaskOutput works for long-running tasks
  - Title extraction from HTML <title> tags needs cleanup (remove site suffix)

---

## PREVIOUS PROJECT: MartiniWorks Build Thread Scraper (COMPLETED)
- Successfully scraped 999 build threads from martiniworks.com
- Files archived in: scraped_builds/martiniworks/
- Learnings from that project:
  - Selenium required for infinite scroll pages
  - Use `--headless=new` for modern Chrome headless mode
  - requests library is lighter than Selenium for simple HTTP fetching
  - Progress file allows resuming interrupted scrapes
  - Rate limiting (1.5s delay) is important for respectful scraping
  - Retry strategy with backoff helps handle transient failures
  - Scraping 1000 URLs with 1.5s delay takes ~30 minutes

---
